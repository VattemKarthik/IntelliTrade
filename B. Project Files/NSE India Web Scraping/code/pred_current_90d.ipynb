{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score\n",
    "from datetime import date,timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_data_dir=\"D:\\\\programs\\\\Applied data Science\\\\proj\\\\logres_op\\\\data\"\n",
    "read_model_dir=\"D:\\\\programs\\\\Applied data Science\\\\proj\\\\logres_op\\\\model\"\n",
    "res_save_dir=\"D:\\\\programs\\\\Applied data Science\\\\proj\\\\logres_op\\\\90_day_pred\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls=[]\n",
    "files=[]\n",
    "for root, dirs, files in os.walk(read_data_dir, topdown=False):\n",
    "   for name in files:\n",
    "      ls.append(os.path.join(root, name))\n",
    "for i in range(len(files)):\n",
    "   files[i]=files[i].replace(\".csv\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_m=[]\n",
    "files_m=[]\n",
    "for root, dirs, files_m in os.walk(read_data_dir, topdown=False):\n",
    "   for name in files_m:\n",
    "      ls_m.append(os.path.join(root, name))\n",
    "for i in range(len(files_m)):\n",
    "   files_m[i]=files_m[i].replace(\".h5\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "time=90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2023, 6, 21)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdate=date.today()\n",
    "cdate=cdate.replace(day=cdate.day-7)\n",
    "cdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates=[]\n",
    "for i in range(time):\n",
    "    dates.append(cdate.strftime('%d/%m/%Y'))\n",
    "    cdate=cdate.replace(year=2023)+timedelta(days=1)\n",
    "    # print(cdate)\n",
    "# type(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\programs\\\\Applied data Science\\\\proj\\\\logres_op\\\\data\\\\LT.csv',\n",
       " 'D:\\\\programs\\\\Applied data Science\\\\proj\\\\logres_op\\\\data\\\\MARUTI.csv',\n",
       " 'D:\\\\programs\\\\Applied data Science\\\\proj\\\\logres_op\\\\data\\\\M_M.csv',\n",
       " 'D:\\\\programs\\\\Applied data Science\\\\proj\\\\logres_op\\\\data\\\\NESTLEIND.csv',\n",
       " 'D:\\\\programs\\\\Applied data Science\\\\proj\\\\logres_op\\\\data\\\\NTPC.csv',\n",
       " 'D:\\\\programs\\\\Applied data Science\\\\proj\\\\logres_op\\\\data\\\\ONGC.csv',\n",
       " 'D:\\\\programs\\\\Applied data Science\\\\proj\\\\logres_op\\\\data\\\\POWERGRID.csv',\n",
       " 'D:\\\\programs\\\\Applied data Science\\\\proj\\\\logres_op\\\\data\\\\RELIANCE.csv',\n",
       " 'D:\\\\programs\\\\Applied data Science\\\\proj\\\\logres_op\\\\data\\\\SBILIFE.csv',\n",
       " 'D:\\\\programs\\\\Applied data Science\\\\proj\\\\logres_op\\\\data\\\\SBIN.csv',\n",
       " 'D:\\\\programs\\\\Applied data Science\\\\proj\\\\logres_op\\\\data\\\\SUNPHARMA.csv',\n",
       " 'D:\\\\programs\\\\Applied data Science\\\\proj\\\\logres_op\\\\data\\\\TATACONSUM.csv',\n",
       " 'D:\\\\programs\\\\Applied data Science\\\\proj\\\\logres_op\\\\data\\\\TATAMOTORS.csv',\n",
       " 'D:\\\\programs\\\\Applied data Science\\\\proj\\\\logres_op\\\\data\\\\TATASTEEL.csv',\n",
       " 'D:\\\\programs\\\\Applied data Science\\\\proj\\\\logres_op\\\\data\\\\TCS.csv',\n",
       " 'D:\\\\programs\\\\Applied data Science\\\\proj\\\\logres_op\\\\data\\\\TECHM.csv',\n",
       " 'D:\\\\programs\\\\Applied data Science\\\\proj\\\\logres_op\\\\data\\\\TITAN.csv',\n",
       " 'D:\\\\programs\\\\Applied data Science\\\\proj\\\\logres_op\\\\data\\\\ULTRACEMCO.csv',\n",
       " 'D:\\\\programs\\\\Applied data Science\\\\proj\\\\logres_op\\\\data\\\\UPL.csv',\n",
       " 'D:\\\\programs\\\\Applied data Science\\\\proj\\\\logres_op\\\\data\\\\WIPRO.csv']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls[30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    }
   ],
   "source": [
    "for v in range(50):\n",
    "    dfr=pd.read_csv(ls[v])\n",
    "    dfr.drop(\"Unnamed: 0\",axis=1,inplace=True)\n",
    "    rl=tf.keras.models.load_model(\"D:\\\\programs\\\\Applied data Science\\\\proj\\\\logres_op\\\\model\\\\\"+files[v]+\".h5\")\n",
    "    op=rl.predict(np.array(dfr[\"logret\"][dfr[\"logret\"].size-90:]).reshape(1,time,1))\n",
    "    op=((math.e**pd.DataFrame(op,index=[\"predicted value\"],columns=dates).T)*dfr[\"close \"][dfr[\"close \"].size-1])\n",
    "    # op.to_csv(res_save_dir+\"\\\\\"+files[v]+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
